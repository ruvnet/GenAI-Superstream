# Default configuration for GenAI-Superstream

# Model configuration
model:
  type: "logistic_regression"
  params:
    max_iter: 200
    C: 1.0
    random_state: 42
    
# Server configuration
server:
  host: "0.0.0.0"
  port: 7860
  share: false
  mcp_server: true
  show_error_details: true
  
# Client configuration
client:
  server_url: "http://localhost:7860/gradio_api/mcp/sse"
  timeout: 30
  retry_attempts: 3
  retry_delay: 2
  
# Logging configuration
logging:
  level: "INFO"
  file: "logs/genai-superstream.log"

# Data preprocessing configuration
preprocessing:
  scaling_strategy: null  # Options: null, "standard", "minmax"
  test_size: 0.2
  random_state: 42